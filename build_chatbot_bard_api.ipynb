{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPzo35u7hJ0zmHv/i+n9CNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahmiraz/chatbot-google-generative-ai/blob/main/build_chatbot_bard_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "885AZxB6ttXQ",
        "outputId": "fd755068-096a-4358-8af0-127ed17019ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.61.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.59.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as palm\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "nP6nICY9tvK4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palm.configure(api_key='AIzaSyAcEViPJjklrV0uc4rpM-hwFUw9Oo7ydFE')"
      ],
      "metadata": {
        "id": "uZh4bljnuFML"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the palm.list_models function to find available models:\n",
        "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
        "model = models[0].name\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1vP4lgIuNpi",
        "outputId": "cdad90cd-7e1c-4038-8f33-8ecba301af33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/text-bison-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Simple Chatbot**"
      ],
      "metadata": {
        "id": "6gdB4NULuS-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = input(\"Enter your question and what do you expect? : \")\n",
        "\n",
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGlzC9gyubMB",
        "outputId": "6481c051-bc56-4e7f-d318-b4780c519329"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question and what do you expect? : teach me what is google's generative ai in 5 lines\n",
            "Google's generative AI is a technology that uses artificial intelligence to create human-like text, images, and other content. It's used in a variety of applications, from customer service to content creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Text Summrizer**"
      ],
      "metadata": {
        "id": "RXkMCzZDvZpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj3OJg3mvhpK",
        "outputId": "300424f7-7b2f-41b2-853c-963d36960141"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/277.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/277.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader"
      ],
      "metadata": {
        "id": "vW50UqhavliU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChFEk_TgvqiY",
        "outputId": "5df5ea88-913b-4305-abfb-92d951924cdf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/Colab-Notebooks/Build-A-Chatbot-Project-Bard-API/'\n",
        "filename  = 'Attention-Is-All-You-Need.pdf'\n",
        "# filename  = 'Art-of-War.pdf'"
      ],
      "metadata": {
        "id": "_ZKXg0PjvsTk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pdf file object\n",
        "pdfFileObject = open(directory+filename, 'rb')\n",
        "# creating a pdf reader object\n",
        "pdfReader = PdfReader(pdfFileObject)\n",
        "text=[]\n",
        "summary=' '\n",
        "#Storing the pages in a list\n",
        "for i in range(0,len(pdfReader.pages)):\n",
        "  # creating a page object\n",
        "  pageObj = pdfReader.pages[i].extract_text()\n",
        "  pageObj= pageObj.replace('\\t\\r','')\n",
        "  pageObj= pageObj.replace('\\xa0','')\n",
        "  # extracting text from page\n",
        "  text.append(pageObj)"
      ],
      "metadata": {
        "id": "SbVlYvzuv45x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge multiple page - to reduce API Calls\n",
        "def join_elements(lst, chars_per_element):\n",
        "    new_lst = []\n",
        "    for i in range(0, len(lst), chars_per_element):\n",
        "        new_lst.append(''.join(lst[i:i+chars_per_element]))\n",
        "    return new_lst\n",
        "\n",
        "# Option to keep x elements per list element\n",
        "new_text = join_elements(text, 3)\n",
        "\n",
        "print(f\"Original Pages = \",len(text))\n",
        "print(f\"Compressed Pages = \",len(new_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c7APyHpyupm",
        "outputId": "ae7937c9-898c-48f3-cae0-d140ca2c116a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Pages =  15\n",
            "Compressed Pages =  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt):\n",
        "  completion = palm.generate_text(model=model,\n",
        "                                  prompt=prompt,\n",
        "                                  temperature=0,\n",
        "                                  # The maximum length of the response\n",
        "                                  max_output_tokens=200,\n",
        "                                  )\n",
        "  return completion.result"
      ],
      "metadata": {
        "id": "95PzqdIWyy-F"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = \"\"\n",
        "for i in range(len(new_text)):\n",
        "  prompt =f\"\"\"\n",
        "  Your task is to act as a Text Summariser.\n",
        "  I'll give you text from  pages of a book from beginning to end.\n",
        "  And your job is to summarise text from these pages in less than 100 words.\n",
        "  Don't be conversational. I need a plain 100 word answer.\n",
        "  Text is shared below, delimited with triple backticks:\n",
        "  ```{text[i]}```\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = get_completion(prompt)\n",
        "  except:\n",
        "    response = get_completion(prompt)\n",
        "  print(response)\n",
        "  summary= f\"{summary} {response}\\n\\n\"\n",
        "  # result.append(response)\n",
        "  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bNckgADvy1vn",
        "outputId": "e0e8846d-19da-4888-9f85-851e186f1423"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer is a new neural network architecture for sequence transduction tasks. It is based on attention mechanisms and does not use recurrence or convolutions. It achieves state-of-the-art results on machine translation and constituency parsing tasks.\n",
            "Transformer is a new neural network architecture for sequence transduction tasks. It eschews recurrence and instead relies entirely on an attention mechanism to draw global dependencies between input and output.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c5d484350758>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf\"{summary} {response}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# result.append(response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#You can query the model only 3 times in a minute for free, so we need to put some delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(directory +'/palm_api_summary.txt',\n",
        "          'w') as out:\n",
        "  out.write(summary)"
      ],
      "metadata": {
        "id": "An6hrV5wzDli"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mock Interviewer chatbot**"
      ],
      "metadata": {
        "id": "JjofVaD4zGaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domain = input(\"Enter the field which you are doing interview ?: (ex. Software engineering: )\")\n",
        "quantity  = input(\"How many questions ?\")\n",
        "prompt = f\"\"\"\n",
        "  you are a very expert in taking interview and asking question to check candidates.\n",
        "  you are going to take interview and ask question regarding the {domain} and {quantity} questions. Ask questions only\n",
        "\"\"\"\n",
        "\n",
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "\n",
        "# Print the questions\n",
        "print(completion.result)\n",
        "\n",
        "# Print a newline\n",
        "print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "# Get the answer from the user\n",
        "answer = input(\"Answer: \")\n",
        "\n",
        "# Prompt Palm to check the answer and provide feedback\n",
        "prompt = f\"\"\" Check the answers {answer}\n",
        "   if its not correct explain a little bit or give hints\n",
        "\"\"\"\n",
        "\n",
        "# Generate feedback\n",
        "completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        ")\n",
        "print(\"--------------------------------------------\\nAnswer by AI\")\n",
        "print(completion.result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDf889bzKho",
        "outputId": "cf423404-3750-4268-f0ec-ee64ad3ee07c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the field which you are doing interview ?: (ex. Software engineering: )cs\n",
            "How many questions ?5\n",
            "1. Why do you want to work in the field of computer science?\n",
            "2. What are your strengths and weaknesses as a computer scientist?\n",
            "3. What are your goals for the future?\n",
            "4. What are your salary expectations?\n",
            "5. What are your thoughts on the current state of the tech industry?\n",
            "--------------------------------------------------\n",
            "\n",
            "Answer: dont know, answer all\n",
            "--------------------------------------------\n",
            "  1. What is the capital of France? Paris\n",
            "2. Who is the president of the United States? Joe Biden\n",
            "3. What is the largest ocean in the world? Pacific Ocean\n",
            "4. What is the highest mountain in the world? Mount Everest\n",
            "5. What is the chemical formula for water? H2O\n"
          ]
        }
      ]
    }
  ]
}